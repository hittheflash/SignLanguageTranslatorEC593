{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "from frame import files2frames, video2frames, frames_show, frames_show2, image_crop, images_crop, video_length, frames_downsample\n",
    "from timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpticalFlow:\n",
    "    \"\"\" Initialize an OpticalFlow object, \n",
    "    then use next() to calculate optical flow from subsequent frames.\n",
    "    Detects first call automatically.\n",
    "    \"\"\" \n",
    "    def __init__(self, sAlgorithm:str = \"tvl1-fast\", bThirdChannel:bool = False, fBound:float = 20.):\n",
    "        self.bThirdChannel = bThirdChannel\n",
    "        self.fBound = fBound\n",
    "        self.arPrev = np.zeros((1,1))\n",
    "\n",
    "        if sAlgorithm == \"tvl1-fast\":\n",
    "            self.oTVL1 = cv2.optflow.DualTVL1OpticalFlow_create(\n",
    "                scaleStep = 0.5, warps = 3, epsilon = 0.02)\n",
    "                # Mo 25.6.2018: (theta = 0.1, nscales = 1, scaleStep = 0.3, warps = 4, epsilon = 0.02)\n",
    "                # Very Fast (theta = 0.1, nscales = 1, scaleStep = 0.5, warps = 1, epsilon = 0.1)\n",
    "            sAlgorithm = \"tvl1\"\n",
    "\n",
    "        elif sAlgorithm == \"tvl1-warps1\":\n",
    "            self.oTVL1 = cv2.optflow.DualTVL1OpticalFlow_create(warps = 1)\n",
    "            sAlgorithm = \"tvl1\"\n",
    "\n",
    "        elif sAlgorithm == \"tvl1-quality\":\n",
    "            self.oTVL1 = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "                # Default: (tau=0.25, lambda=0.15, theta=0.3, nscales=5, warps=5, epsilon=0.01, \n",
    "                #innnerIterations=30, outerIterations=10, scaleStep=0.8, gamma=0.0, \n",
    "                #medianFiltering=5, useInitialFlow=False)\n",
    "            sAlgorithm = \"tvl1\"\n",
    "\n",
    "        elif sAlgorithm == \"farnback\":\n",
    "            pass\n",
    "\n",
    "        else: raise ValueError(\"Unknown optical flow type\")\n",
    "        \n",
    "        self.sAlgorithm = sAlgorithm\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def first(self, arImage:np.array) -> np.array:\n",
    "\n",
    "        h, w, _ = arImage.shape\n",
    "\n",
    "        # save first image in black&white\n",
    "        self.arPrev = cv2.cvtColor(arImage, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # first flow = zeros\n",
    "        arFlow = np.zeros((h, w, 2), dtype = np.float32)\n",
    "\n",
    "        if self.bThirdChannel:\n",
    "            self.arZeros = np.zeros((h, w, 1), dtype = np.float32)\n",
    "            arFlow = np.concatenate((arFlow, self.arZeros), axis=2) \n",
    "\n",
    "        return arFlow\n",
    "\n",
    "\n",
    "    def next(self, arImage:np.array) -> np.array:\n",
    "\n",
    "        # first?\n",
    "        if self.arPrev.shape == (1,1): return self.first(arImage)\n",
    "\n",
    "        # get image in black&white\n",
    "        arCurrent = cv2.cvtColor(arImage, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if self.sAlgorithm == \"tvl1\":\n",
    "            arFlow = self.oTVL1.calc(self.arPrev, arCurrent, None)\n",
    "        elif self.sAlgorithm == \"farnback\":\n",
    "            arFlow = cv2.calcOpticalFlowFarneback(self.arPrev, arCurrent, flow=None, \n",
    "                pyr_scale=0.5, levels=1, winsize=15, iterations=2, poly_n=5, poly_sigma=1.1, flags=0)\n",
    "        else: raise ValueError(\"Unknown optical flow type\")\n",
    "\n",
    "        # only 2 dims\n",
    "        arFlow = arFlow[:, :, 0:2]\n",
    "\n",
    "        # truncate to +/-15.0, then rescale to [-1.0, 1.0]\n",
    "        arFlow[arFlow > self.fBound] = self.fBound \n",
    "        arFlow[arFlow < -self.fBound] = -self.fBound\n",
    "        arFlow = arFlow / self.fBound\n",
    "\n",
    "        if self.bThirdChannel:\n",
    "            # add third empty channel\n",
    "            arFlow = np.concatenate((arFlow, self.arZeros), axis=2) \n",
    "\n",
    "        self.arPrev = arCurrent\n",
    "\n",
    "        return arFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow2colorimage(ar_f_Flow:np.array(float)) -> np.array(int):\n",
    "    \"\"\" translate 1 optical flow (with values from -1.0 to 1.0) to an colorful image\n",
    "    \"\"\"\n",
    "\n",
    "    h, w, c = ar_f_Flow.shape\n",
    "    if not isinstance(ar_f_Flow[0,0,0], np.float32): \n",
    "        warnings.warn(\"Need to convert flows to float32\")\n",
    "        ar_f_Flow = ar_f_Flow.astype(np.float32)\n",
    "\n",
    "    ar_n_hsv = np.zeros((h, w, 3), dtype = np.uint8)\n",
    "    ar_n_hsv[...,1] = 255\n",
    "\n",
    "    # get colors\n",
    "    mag, ang = cv2.cartToPolar(ar_f_Flow[..., 0], ar_f_Flow[..., 1])\n",
    "    ar_n_hsv[...,0] = ang * 180 / np.pi / 2\n",
    "    ar_n_hsv[...,2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    ar_n_bgr = cv2.cvtColor(ar_n_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return ar_n_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames2flows(arFrames:np.array(int), sAlgorithm = \"tvl1-fast\", bThirdChannel:bool = False, bShow = False, fBound:float = 20.) -> np.array(float):\n",
    "    \"\"\" Calculates optical flow from frames\n",
    "\n",
    "    Returns:\n",
    "        array of flow-arrays, each with dim (h, w, 2), \n",
    "        with \"flow\"-values truncated to [-15.0, 15.0] and then scaled to [-1.0, 1.0]\n",
    "        If bThirdChannel = True a third channel with zeros is added\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize optical flow calculation\n",
    "    oOpticalFlow = OpticalFlow(sAlgorithm = sAlgorithm, bThirdChannel = bThirdChannel, fBound = fBound)\n",
    "    \n",
    "    liFlows = []\n",
    "    # loop through all frames\n",
    "    for i in range(len(arFrames)):\n",
    "        # calc dense optical flow\n",
    "        arFlow = oOpticalFlow.next(arFrames[i, ...])\n",
    "        liFlows.append(arFlow)\n",
    "        if bShow:\n",
    "            cv2.imshow(\"Optical flow\", flow2colorimage(arFlow))\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    return np.array(liFlows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flows_add_third_channel(arFlows:np.array) -> np.array:\n",
    "    \"\"\" add third empty channel to array of flows\n",
    "    \"\"\"\n",
    "    \n",
    "    n, h, w, c = arFlows.shape\n",
    "    if c != 2: raise ValueError(\"Expected 2 channels, not %d\" % c)\n",
    "    \n",
    "    arZeros = np.zeros((n, h, w, 1), dtype = np.float32)\n",
    "    arFlows3 = np.concatenate((arFlows, arZeros), axis=3)\n",
    "\n",
    "    return arFlows3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flows2file(arFlows:np.array(float), sTargetDir:str):\n",
    "    \"\"\" Save array of flows (2 channels with values in [-1.0, 1.0]) \n",
    "    to jpg files (with 3 channels 0-255 each) in sTargetDir\n",
    "    \"\"\"\n",
    "\n",
    "    n, h, w, c = arFlows.shape\n",
    "\n",
    "    os.makedirs(sTargetDir, exist_ok=True)\n",
    "\n",
    "    arZeros = np.zeros((h, w, 1), dtype = np.float32)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        # add third empty channel\n",
    "        ar_f_Flow = np.concatenate((arFlows[i, ...], arZeros), axis=2)\n",
    "\n",
    "        # rescale to 0-255  \n",
    "        ar_n_Flow = np.round((ar_f_Flow + 1.0) * 127.5).astype(np.uint8)\n",
    "\n",
    "        cv2.imwrite(sTargetDir + \"/flow%03d.jpg\"%(i), ar_n_Flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2flows(sDir:str, b3channels:bool = False) -> np.array:\n",
    "    \"\"\" Read flow files from directory\n",
    "    Expects 3-channel jpg files\n",
    "    Output\n",
    "        Default: array with 2-channel flow, with floats between [-1.0, 1.0]\n",
    "        If b3channels = True: including 3rd channel from jpeg (should result in zero values)\n",
    "    \"\"\"\n",
    "\n",
    "    # important to sort flow files upfront\n",
    "    liFiles = sorted(glob.glob(sDir + \"/*.jpg\"))\n",
    "\n",
    "    #liFilesU = sorted(glob.glob(sDir + \"/u/*.jpg\"))\n",
    "    #liFilesV = sorted(glob.glob(sDir + \"/v/*.jpg\"))\n",
    "\n",
    "    if len(liFiles) == 0: raise ValueError(\"No optical flow files found in \" + sDir)\n",
    "    #if len(liFilesU) != len(liFilesV): raise ValueError(\"Flow files: same number expected in u and v\")\n",
    "\n",
    "    liFlows = []\n",
    "    # loop through frames\n",
    "    for i in range(len(liFiles)):\n",
    "\n",
    "        ar_n_Flow = cv2.imread(liFiles[i])\n",
    "        h, w, c = ar_n_Flow.shape\n",
    "\n",
    "        # optical flow only 2-dim\n",
    "        if not b3channels: \n",
    "            ar_n_Flow = ar_n_Flow[:,:,0:2]\n",
    "\n",
    "        # rescale from 0-255 to [-15.0, 15.0]\n",
    "        ar_f_Flow = ((ar_n_Flow / 127.5) - 1.).astype(np.float32)\n",
    "        #print(\"Ori: %3dto%3d | Rescaled: %4.1fto%4.1f\" % \\\n",
    "        #    (np.min(ar_n_Flow), np.max(ar_n_Flow), np.min(ar_f_Flow), np.max(ar_f_Flow)))\n",
    "\n",
    "        #arU = cv2.imread(liFilesU[i], cv2.IMREAD_GRAYSCALE)\n",
    "        #arV = cv2.imread(liFilesV[i], cv2.IMREAD_GRAYSCALE)\n",
    "        #arFlow = np.concatenate((arU[:,:,np.newaxis], arV[:,:,np.newaxis]), axis=2)\n",
    "        \n",
    "        liFlows.append(ar_f_Flow)\n",
    "\n",
    "    return np.array(liFlows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flows2colorimages(arFlows:np.array) -> np.array:\n",
    "    \"\"\" translate many optical flows to colorful images\n",
    "    \"\"\"\n",
    "    n, _, _, _ = arFlows.shape\n",
    "    liImages = []\n",
    "    for i in range(n):\n",
    "        arImage = flow2colorimage(arFlows[i, ...])\n",
    "        liImages.append(arImage)\n",
    "    return np.array(liImages)\n",
    "\n",
    "def framesDir2flowsDir(sFrameBaseDir:str, sFlowBaseDir:str, nFramesNorm:int = None, sAlgorithm:str = \"tvl1-fast\"):\n",
    "    \"\"\" Calculate optical flow from frames (extracted from videos) \n",
    "    \n",
    "    Input videoframe structure:\n",
    "    ... sFrameDir / train / class001 / videoname / frames.jpg\n",
    "\n",
    "    Output:\n",
    "    ... sFlowDir / train / class001 / videoname / flow.jpg\n",
    "    \"\"\"\n",
    "\n",
    "    # do not (partially) overwrite existing directory\n",
    "    #if os.path.exists(sFlowBaseDir): \n",
    "    #    warnings.warn(\"\\nOptical flow folder \" + sFlowBaseDir + \" alredy exists: flow calculation stopped\")\n",
    "    #    return\n",
    "\n",
    "    # get list of directories with frames: ... / sFrameDir/train/class/videodir/frames.jpg\n",
    "    sCurrentDir = os.getcwd()\n",
    "    os.chdir(sFrameBaseDir)\n",
    "    liVideos = sorted(glob.glob(\"*/*/*\"))\n",
    "    os.chdir(sCurrentDir)\n",
    "    print(\"Found %d directories=videos with frames in %s\" % (len(liVideos), sFrameBaseDir))\n",
    "\n",
    "    # loop over all videos-directories\n",
    "    nCounter = 0\n",
    "    for sFrameDir in liVideos:\n",
    "\n",
    "        # generate target directory\n",
    "        sFlowDir = sFlowBaseDir + \"/\" + sFrameDir\n",
    "\n",
    "        if nFramesNorm != None and os.path.exists(sFlowDir):\n",
    "            nFlows = len(glob.glob(sFlowDir + \"/*.*\"))\n",
    "            if nFlows == nFramesNorm: \n",
    "                print(\"Video %5d: optical flow already extracted to %s\" % (nCounter, sFlowDir))\n",
    "                nCounter += 1\n",
    "                continue\n",
    "            else: \n",
    "                print(\"Video %5d: Directory with %d instead of %d flows detected\" % (nCounter, nFlows, nFramesNorm))\n",
    "\n",
    "        # retrieve frame files - in ascending order\n",
    "        arFrames = files2frames(sFrameBaseDir + \"/\" + sFrameDir)\n",
    "\n",
    "        # downsample\n",
    "        if nFramesNorm != None: \n",
    "            arFrames = frames_downsample(arFrames, nFramesNorm)\n",
    "\n",
    "        # calculate and save optical flow\n",
    "        print(\"Video %5d: Calc optical flow with %s from %s frames to %s\" % (nCounter, sAlgorithm, str(arFrames.shape), sFlowDir))\n",
    "        arFlows = frames2flows(arFrames, sAlgorithm = sAlgorithm)\n",
    "        flows2file(arFlows, sFlowDir)\n",
    "\n",
    "        nCounter += 1      \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unittest_fromfile():\n",
    "    print(\"Unittest opticalflow functions ...\")\n",
    "    timer = Timer()\n",
    "\n",
    "    # read test video and show it\n",
    "    liVideosDebug = glob.glob(\"data-set/04-chalearn/010/train/010/*.*\")\n",
    "    sVideoFile = random.choice(liVideosDebug)\n",
    "    fLength = video_length(sVideoFile)\n",
    "    arFrames = video2frames(sVideoFile, nResizeMinDim = 240)\n",
    "    \n",
    "    print(\"Video: %.1f sec | %s | %s\" % (fLength, str(arFrames.shape), sVideoFile))\n",
    "    frames_show(arFrames, int(fLength * 1000 / len(arFrames)))\n",
    "\n",
    "    # calc flow and save to disc\n",
    "    print(\"Calculating optical flow ...\")\n",
    "    timer.start()\n",
    "    arFlows = frames2flows(arFrames)\n",
    "    print(\"Optical flow per frame: %.3f\" % (timer.stop() / len(arFrames)))\n",
    "\n",
    "    #flows2file(arFlows, \"data-temp/unittest\")\n",
    "\n",
    "    # show color flows\n",
    "    arFlowImages = flows2colorimages(arFlows)\n",
    "    frames_show(arFlowImages, int(fLength * 1000 / len(arFrames)))  \n",
    "\n",
    "    # read flows from directory and display\n",
    "    #arFlows2 = file2flows(\"data-temp/unittest\", b3channels=True)\n",
    "    #print(arFlows2.shape, np.mean(arFlows2[:,:,:,2]))\n",
    "    #frames_show(arFlows2, 50)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unittest opticalflow functions ...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-98cd62623c58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munittest_fromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-d313256f6a62>\u001b[0m in \u001b[0;36munittest_fromfile\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# read test video and show it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mliVideosDebug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data-set/04-chalearn/010/train/010/*.*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msVideoFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliVideosDebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mfLength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msVideoFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0marFrames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo2frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msVideoFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnResizeMinDim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m240\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "unittest_fromfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frames_show_(arFrames:np.array, nWaitMilliSec:int = 1):\n",
    "\n",
    "    nFrames, nHeight, nWidth, nDepth = arFrames.shape\n",
    "    \n",
    "    for i in range(nFrames):\n",
    "        cv2.imshow(\"Frame\", arFrames[i, :, :, :])\n",
    "        key = cv2.waitKey(50)#pauses for 3 seconds before fetching next image\n",
    "        if key == 27:#if ESC is pressed, exit loop\n",
    "            break\n",
    "            cv2.destroyAllWindows()\n",
    "    cv2.destroyAllWindows()\n",
    "            \n",
    "\n",
    "\"\"\"            \n",
    "def frames_show(arFrames:np.array, nWaitMilliSec:int = 1):\n",
    "\n",
    "    nFrames, nHeight, nWidth, nDepth = arFrames.shape\n",
    "    \n",
    "    for i in range(nFrames):\n",
    "        cv2.imshow(\"Frame\", arFrames[i, :, :, :])\n",
    "        cv2.waitKey(0)\n",
    "        if i==nFrames-2:\n",
    "            break\n",
    "    #a = True\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_show2(arFrames:np.array, nWaitMilliSec:int = 1):\n",
    "\n",
    "    nFrames, nHeight, nWidth, nDepth = arFrames.shape\n",
    "    i = 0\n",
    "    k = nFrames - (nFrames - i)\n",
    "    while k < nFrames:\n",
    "        \n",
    "        cv2.imshow('my webcam', arFrames[k, :, :, :])\n",
    "        cv2.waitKey(1)\n",
    "        i+=1\n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"Unittest opticalflow functions ...\")\n",
    "timer = Timer()\n",
    "\n",
    "# read test video and show it\n",
    "liVideosDebug = glob.glob(\"data-set/04-chalearn/010/train/010/*.*\")\n",
    "sVideoFile = random.choice(liVideosDebug)\n",
    "fLength = video_length(sVideoFile)\n",
    "video = \"alex.mp4\"\n",
    "#arFrames = video2frames(sVideoFile, nResizeMinDim = 240)\n",
    "arFrames = video2frames(video, nResizeMinDim = 240)\n",
    "\n",
    "print(\"Video: %.1f sec | %s | %s\" % (fLength, str(arFrames.shape), sVideoFile))\n",
    "frames_show(arFrames, int(fLength * 1000 / len(arFrames)))\n",
    "\"\"\" \n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video2 = \"karen3.mp4\"\n",
    "video = 'K_01801.avi'\n",
    "vid = 'poses_b/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating optical flow ...\n",
      "Execution time: 9.12 sec\n",
      "Optical flow per frame: 0.163\n"
     ]
    }
   ],
   "source": [
    "#arFrames = video2frames(sVideoFile, nResizeMinDim = 240)\n",
    "arFrames = video2frames(video, nResizeMinDim = 240)\n",
    "fLength = video_length(video)\n",
    "\n",
    "# calc flow and save to disc\n",
    "print(\"Calculating optical flow ...\")\n",
    "timer = Timer()\n",
    "timer.start()\n",
    "arFlows = frames2flows(arFrames)\n",
    "print(\"Optical flow per frame: %.3f\" % (timer.stop() / len(arFrames)))\n",
    "\n",
    "#flows2file(arFlows, \"data-temp/unittest\")\n",
    "\n",
    "# show color flows\n",
    "arFlowImages2 = flows2colorimages(arFlows)\n",
    "frames_show(arFlowImages, int(fLength * 1000 / len(arFrames)))  \n",
    "\n",
    "# read flows from directory and display\n",
    "#arFlows2 = file2flows(\"data-temp/unittest\", b3channels=True)\n",
    "#print(arFlows2.shape, np.mean(arFlows2[:,:,:,2]))\n",
    "#frames_show(arFlows2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_show(arFlowImages, int(fLength * 1000 / len(arFrames)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_show(arFlowImages2, int(fLength * 1000 / len(arFrames)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames2flows(arFrames:np.array(int), sAlgorithm = \"tvl1-fast\", bThirdChannel:bool = False, bShow = False, fBound:float = 20.) -> np.array(float):\n",
    "    \"\"\" Calculates optical flow from frames\n",
    "\n",
    "    Returns:\n",
    "        array of flow-arrays, each with dim (h, w, 2), \n",
    "        with \"flow\"-values truncated to [-15.0, 15.0] and then scaled to [-1.0, 1.0]\n",
    "        If bThirdChannel = True a third channel with zeros is added\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize optical flow calculation\n",
    "    oOpticalFlow = OpticalFlow(sAlgorithm = sAlgorithm, bThirdChannel = bThirdChannel, fBound = fBound)\n",
    "    \n",
    "    liFlows = []\n",
    "    # loop through all frames\n",
    "    for i in range(len(arFrames)):\n",
    "        # calc dense optical flow\n",
    "        arFlow = oOpticalFlow.next(arFrames[i, ...])\n",
    "        liFlows.append(arFlow)\n",
    "        if bShow:\n",
    "            cv2.imshow(\"Optical flow\", flow2colorimage(arFlow))\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    return np.array(liFlows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6b992b56e595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframes2flows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Display the resulting frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-98a77de2324a>\u001b[0m in \u001b[0;36mframes2flows\u001b[1;34m(arFrames, sAlgorithm, bThirdChannel, bShow, fBound)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marFrames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# calc dense optical flow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0marFlow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moOpticalFlow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marFrames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mliFlows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marFlow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbShow\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-acf5b2ff326d>\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, arImage)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# first?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# get image in black&white\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-acf5b2ff326d>\u001b[0m in \u001b[0;36mfirst\u001b[1;34m(self, arImage)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marImage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# save first image in black&white\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    frame = frames2flows(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
